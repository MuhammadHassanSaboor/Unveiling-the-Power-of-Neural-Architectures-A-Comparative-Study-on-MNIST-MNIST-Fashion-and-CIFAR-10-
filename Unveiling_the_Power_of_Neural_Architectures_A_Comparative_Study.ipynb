{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vohNhXUdv-t"
      },
      "source": [
        "# Unveiling the Power of Neural Architectures: A Comparative Study\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6mgo2kQd1L0"
      },
      "source": [
        "#Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lfdAGD8hdWhZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6O9NwWEeFvH"
      },
      "source": [
        "#Importing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mGZM1csceDzW",
        "outputId": "dbdd3116-23a4-4fc8-be3c-fd73b06cfe7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aH_fYdS-epZ0",
        "outputId": "74f4a83b-96eb-4739-f71f-471a2af77cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST Fashion dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images_fashion, train_labels_fashion), (test_images_fashion, test_labels_fashion) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l_NFj5N-er6h",
        "outputId": "de0c7a3f-5865-48b7-dc70-8b6464a4bd39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(train_images_cifar10, train_labels_cifar10), (test_images_cifar10, test_labels_cifar10) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9eZaYdoez2A"
      },
      "source": [
        "#Single Layer Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHVBYDLye2zp"
      },
      "source": [
        "Single Layer Network on MNIST Handwritten Digit Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efv8_8HKeub2"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Architecture\n",
        "model_single_layer = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model_single_layer.compile(optimizer='adam',\n",
        "                           loss='sparse_categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_single_layer = model_single_layer.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Testing\n",
        "test_loss, test_acc = model_single_layer.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy (Single Layer): {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAqRJFnWfPUo"
      },
      "source": [
        "Single Layer Network on MNIST Fashion Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhXQ-3uJfT4l"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "train_images_fashion = train_images_fashion.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images_fashion = test_images_fashion.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Architecture\n",
        "model_single_layer_fashion = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model_single_layer_fashion.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_single_layer_fashion = model_single_layer_fashion.fit(train_images_fashion, train_labels_fashion, epochs=10, validation_data=(test_images_fashion, test_labels_fashion))\n",
        "\n",
        "# Testing\n",
        "test_loss_fashion, test_acc_fashion = model_single_layer_fashion.evaluate(test_images_fashion, test_labels_fashion)\n",
        "print(f\"Test Accuracy (Single Layer): {test_acc_fashion}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drWv3vtpfiOS"
      },
      "source": [
        "Single Layer Network on Cifar-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDBgSdy3fluJ"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "train_images_cifar10 = train_images_cifar10.astype('float32') / 255\n",
        "test_images_cifar10 = test_images_cifar10.astype('float32') / 255\n",
        "\n",
        "# Architecture\n",
        "model_single_layer_cifar10 = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model_single_layer_cifar10.compile(optimizer='adam',\n",
        "                                   loss='sparse_categorical_crossentropy',\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_single_layer_cifar10 = model_single_layer_cifar10.fit(train_images_cifar10, train_labels_cifar10, epochs=10, validation_data=(test_images_cifar10, test_labels_cifar10))\n",
        "\n",
        "# Testing\n",
        "test_loss_cifar10, test_acc_cifar10 = model_single_layer_cifar10.evaluate(test_images_cifar10, test_labels_cifar10)\n",
        "print(f\"Test Accuracy (Single Layer CIFAR-10): {test_acc_cifar10}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaB4KZRfzSD"
      },
      "source": [
        "#Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhqWR1H0f4dN"
      },
      "source": [
        "Multi Layer Perceptron on MNIST Handwritten Digit dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t85g08Wqf2k2"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Architecture\n",
        "model_mlp = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model_mlp.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_model_mlp = model_mlp.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Testing\n",
        "test_loss_mnist, test_acc_mnist = model_mlp.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy (MLP - MNIST): {test_acc_mnist}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1YNf3tZgHci"
      },
      "source": [
        "Multi Layer Perceptron on MNIST Fashion dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZZ6Jb0GgJzm"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "train_images_fashion = train_images_fashion.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images_fashion = test_images_fashion.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Architecture\n",
        "model_mlp_fashion = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model_mlp_fashion.compile(optimizer='adam',\n",
        "                          loss='sparse_categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_model_mlp_fashion = model_mlp_fashion.fit(train_images_fashion, train_labels_fashion, epochs=10, validation_data=(test_images_fashion, test_labels_fashion))\n",
        "\n",
        "# Testing\n",
        "test_loss_fashion, test_acc_fashion = model_mlp_fashion.evaluate(test_images_fashion, test_labels_fashion)\n",
        "print(f\"Test Accuracy (MLP - Fashion MNIST): {test_acc_fashion}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU5ZpWubgZzx"
      },
      "source": [
        "Multi Layer Perceptron on Cifar-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9kKTny-gbrX"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "train_images_cifar10 = train_images_cifar10.astype('float32') / 255\n",
        "test_images_cifar10 = test_images_cifar10.astype('float32') / 255\n",
        "\n",
        "# Architecture\n",
        "model_mlp_cifar10 = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation\n",
        "model_mlp_cifar10.compile(optimizer='adam',\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_model_mlp_cifar10 = model_mlp_cifar10.fit(train_images_cifar10, train_labels_cifar10, epochs=10, validation_data=(test_images_cifar10, test_labels_cifar10))\n",
        "\n",
        "# ETesting\n",
        "test_loss_cifar10, test_acc_cifar10 = model_mlp_cifar10.evaluate(test_images_cifar10, test_labels_cifar10)\n",
        "print(f\"Test Accuracy (MLP - CIFAR-10): {test_acc_cifar10}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbnYwZlZgwfW"
      },
      "source": [
        "#LeCun's Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_bORRgng-IC"
      },
      "source": [
        "LeCun's Method on MNIST Handwritten Digit Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-FUwhD2g9SZ"
      },
      "outputs": [],
      "source": [
        "# Build the ConvNet based on LeCun's method\n",
        "model_mnist_lecun = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model_mnist_lecun.add(layers.Conv2D(24, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model_mnist_lecun.add(layers.AveragePooling2D((2, 2)))\n",
        "model_mnist_lecun.add(layers.Conv2D(48, (5, 5), activation='relu'))\n",
        "model_mnist_lecun.add(layers.AveragePooling2D((2, 2)))\n",
        "\n",
        "# Fully connected layers\n",
        "model_mnist_lecun.add(layers.Flatten())\n",
        "model_mnist_lecun.add(layers.Dense(256, activation='relu'))\n",
        "model_mnist_lecun.add(layers.Dense(84, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model_mnist_lecun.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compilation\n",
        "model_mnist_lecun.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_model_mnist_lecun = model_mnist_lecun.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Testing\n",
        "test_loss, test_acc = model_mnist_lecun.evaluate(test_images, test_labels)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqFaYBeFhatY"
      },
      "source": [
        "LeCun's Method on MNIST Fashion Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXlqjE2Ihejd"
      },
      "outputs": [],
      "source": [
        "# Build the ConvNet based on LeCun's method\n",
        "model_fashion_lecun = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model_fashion_lecun.add(layers.Conv2D(24, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model_fashion_lecun.add(layers.AveragePooling2D((2, 2)))\n",
        "model_fashion_lecun.add(layers.Conv2D(48, (5, 5), activation='relu'))\n",
        "model_fashion_lecun.add(layers.AveragePooling2D((2, 2)))\n",
        "\n",
        "# Fully connected layers\n",
        "model_fashion_lecun.add(layers.Flatten())\n",
        "model_fashion_lecun.add(layers.Dense(256, activation='relu'))\n",
        "model_fashion_lecun.add(layers.Dense(84, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model_fashion_lecun.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compilation\n",
        "model_fashion_lecun.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_model_fashion_lecun = model_fashion_lecun.fit(train_images_fashion, train_labels_fashion, epochs=10, validation_data=(test_images_fashion, test_labels_fashion))\n",
        "\n",
        "# Testing\n",
        "test_loss, test_acc = model_fashion_lecun.evaluate(test_images_fashion, test_labels_fashion)\n",
        "print(f'\\nTest accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7OelBFohp0j"
      },
      "source": [
        "LeCun's Method on Cifar-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ21Z23Dhz4z"
      },
      "outputs": [],
      "source": [
        "# Build the ConvNet based on LeCun's method for CIFAR-10\n",
        "model_cifar10_lecun = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model_cifar10_lecun.add(layers.Conv2D(24, (5, 5), activation='relu', input_shape=(32, 32, 3)))  # Adjust input shape\n",
        "model_cifar10_lecun.add(layers.AveragePooling2D((2, 2)))\n",
        "model_cifar10_lecun.add(layers.Conv2D(48, (5, 5), activation='relu'))\n",
        "model_cifar10_lecun.add(layers.AveragePooling2D((2, 2)))\n",
        "\n",
        "# Fully connected layers\n",
        "model_cifar10_lecun.add(layers.Flatten())\n",
        "model_cifar10_lecun.add(layers.Dense(256, activation='relu'))\n",
        "model_cifar10_lecun.add(layers.Dense(84, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model_cifar10_lecun.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compilation\n",
        "model_cifar10_lecun.compile(optimizer='adam',\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "history_model_cifar10_lecun = model_cifar10_lecun.fit(train_images_cifar10, train_labels_cifar10, epochs=10, validation_data=(test_images_cifar10, test_labels_cifar10))\n",
        "\n",
        "# Testing\n",
        "test_loss, test_acc = model_cifar10_lecun.evaluate(test_images_cifar10, test_labels_cifar10)\n",
        "print(f'\\nTest accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyGQdiiKh8Nj"
      },
      "source": [
        "#Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-GNXPKNiAz0"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(f'{title} Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(f'{title} Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize Single Layer Network - MNIST\n",
        "plot_history(history_single_layer, 'Single Layer (MNIST)')\n",
        "\n",
        "# Visualize MLP - MNIST\n",
        "plot_history(history_model_mlp, 'MLP (MNIST)')\n",
        "\n",
        "# Visualize LeCun - MNIST\n",
        "plot_history(history_model_mnist_lecun, 'LeCun (MNIST)')\n",
        "\n",
        "# Visualize Single Layer Network - Fashion MNIST\n",
        "plot_history(history_single_layer_fashion, 'Single Layer (Fashion MNIST)')\n",
        "\n",
        "# Visualize MLP - Fashion MNIST\n",
        "plot_history(history_model_mlp_fashion, 'MLP (Fashion MNIST)')\n",
        "\n",
        "# Visualize Lecun - Fashion MNIST\n",
        "plot_history(history_model_fashion_lecun, 'LeCun (Fashion MNIST)')\n",
        "\n",
        "# Visualize Single Layer Network - CIFAR-10\n",
        "plot_history(history_single_layer_cifar10, 'Single Layer (CIFAR-10)')\n",
        "\n",
        "# Visualize MLP - CIFAR-10\n",
        "plot_history(history_model_mlp_cifar10, 'MLP (CIFAR-10)')\n",
        "\n",
        "# Visualize Lecun - CIFAR-10\n",
        "plot_history(history_model_cifar10_lecun, 'LeCun (CIFAR-10)')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
